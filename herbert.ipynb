{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc0a88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from utils.data_utils import preprocessing, custom_train_test_split\n",
    "\n",
    "clean_df = pd.read_csv(\"cleaned_data.csv\", sep=\";\")\n",
    "\n",
    "sns.set_palette(\"rocket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5939bd1-2adc-45c2-884a-4648b5c50f77",
   "metadata": {},
   "source": [
    "## Bins selection\n",
    "\n",
    "Here we will try to come up with the right divisions for bins, since the data doesn't cover the range quite well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218aa890-66d6-4348-8fdb-572068840e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.dropna(subset=['price_pln', 'description'], inplace=True)\n",
    "    df['price_pln'] = pd.to_numeric(\n",
    "        df['price_pln'].astype(str).str.replace(r'[^0-9\\.-]', '', regex=True),\n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf4ea54-e718-4564-9d08-186c2d1fe106",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_data(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1896294-65d8-4043-abb4-3c8ba74bc4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23752, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e7596e-ff27-4bf5-a238-c1515574949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price below 10k: 392\n",
      "Price between 10k‚Äì20k: 1448\n",
      "Price between 20k‚Äì50k: 7125\n",
      "Price between 50k‚Äì75k: 3965\n",
      "Price between 75k‚Äì100k: 2241\n",
      "Price between 100k‚Äì200k: 4158\n",
      "Price above 200k: 4315\n"
     ]
    }
   ],
   "source": [
    "print(f'Price below 10k: {len(data[data['price_pln'] < 10000])}')\n",
    "print(f\"Price between 10k‚Äì20k: {len(data[(data['price_pln'] > 10000) & (data['price_pln'] < 20000)])}\")\n",
    "print(f\"Price between 20k‚Äì50k: {len(data[(data['price_pln'] > 20000) & (data['price_pln'] < 50000)])}\")\n",
    "print(f\"Price between 50k‚Äì75k: {len(data[(data['price_pln'] > 50000) & (data['price_pln'] < 75000)])}\")\n",
    "print(f\"Price between 75k‚Äì100k: {len(data[(data['price_pln'] > 75000) & (data['price_pln'] < 100000)])}\")\n",
    "print(f\"Price between 100k‚Äì200k: {len(data[(data['price_pln'] > 100000) & (data['price_pln'] < 200000)])}\")\n",
    "print(f'Price above 200k: {len(data[data['price_pln'] > 200000])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4f7e4-edc7-45d1-8521-8611140f1c7d",
   "metadata": {},
   "source": [
    "Based on the results above, we opted for the following ranges:\n",
    "\n",
    "- Below 30k\n",
    "- Between 30k and 50k\n",
    "- Between 50k and 75k\n",
    "- Between 75k and 120k\n",
    "- Between 120k and 200k\n",
    "- Above 200k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b61026a1-9941-4cf2-b68f-1417c003d463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price below 30k: 4100\n",
      "Price between 30k‚Äì50k: 4857\n",
      "Price between 50k‚Äì75k: 3965\n",
      "Price between 75k‚Äì120k: 3185\n",
      "Price between 120k‚Äì200k: 3208\n",
      "Price above 200k: 4315\n"
     ]
    }
   ],
   "source": [
    "print(f'Price below 30k: {len(data[data['price_pln'] < 30000])}')\n",
    "print(f\"Price between 30k‚Äì50k: {len(data[(data['price_pln'] > 30000) & (data['price_pln'] < 50000)])}\")\n",
    "print(f\"Price between 50k‚Äì75k: {len(data[(data['price_pln'] > 50000) & (data['price_pln'] < 75000)])}\")\n",
    "print(f\"Price between 75k‚Äì120k: {len(data[(data['price_pln'] > 75000) & (data['price_pln'] < 120000)])}\")\n",
    "print(f\"Price between 120k‚Äì200k: {len(data[(data['price_pln'] > 120000) & (data['price_pln'] < 200000)])}\")\n",
    "print(f'Price above 200k: {len(data[data['price_pln'] > 200000])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a03277d6-5bcd-4011-9471-f7047102df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [\n",
    "    0, 30_000, 50_000, 75_000, 120_000, 200_000, 1_000_000\n",
    "]\n",
    "\n",
    "labels = [0, 1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7183a4c-e20f-4a88-80e9-3702a6a63d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_class'] = pd.cut(\n",
    "    data['price_pln'],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    right=False,\n",
    "    include_lowest=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b9f209f-0932-4734-aab8-1f2fb4fe02bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution\n",
      "price_class\n",
      "0    4100\n",
      "1    4900\n",
      "2    3988\n",
      "3    3226\n",
      "4    3217\n",
      "5    1670\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Distribution\")\n",
    "print(data['price_class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "973768c8-1bfc-4885-973a-931ca9502cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example\n",
      "   price_pln class_label                                        description\n",
      "0    9814170         NaN  grupa tandem\\nul. zuzanny 36\\n41-219 sosnowiec...\n",
      "1      37900     30k-50k  peugeot boxer l4h2 2,2 hdi 165mk klimatyzacja ...\n",
      "2     196500   120k-200k  mercedes-benz grupa wr√≥bel\\nzapraszamy do nasz...\n",
      "3      87945    75k-120k  autoryzowany salon marki opel, firma auto diug...\n",
      "4      47900     30k-50k  nasza aktualna oferta dostƒôpna na stronie:\\n\\n...\n"
     ]
    }
   ],
   "source": [
    "class_map = {\n",
    "    0: '< 30k', 1: '30k-50k', 2: '50k-75k', 3: '75k-120k',\n",
    "    4: '120k-200k', 5: '> 100k'\n",
    "}\n",
    "\n",
    "data['class_label'] = data['price_class'].map(class_map)\n",
    "print(\"\\nExample\")\n",
    "print(data[['price_pln', 'class_label', 'description']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36399c9-3baa-4091-bb12-9cbbbf9a7db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['price_class'], inplace=True)\n",
    "df_classification_herbert = data[['description', 'price_class']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d4fe9-a6ac-48b2-8da2-f229d73818a6",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e218f20-4f90-4f6b-80d0-2a9319506944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50eddd2-078c-4e1d-a20a-65c78bc0637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e12af42-547e-4a08-ba0e-57e1f28207ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbi√≥r treningowy (wiersze): 16880\n",
      "Zbi√≥r walidacyjny (wiersze): 4221\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"allegro/herbert-base-cased\"\n",
    "NUM_LABELS = 6\n",
    "\n",
    "train_df, eval_df = train_test_split(\n",
    "    df_classification_herbert,\n",
    "    test_size=0.2, \n",
    "    stratify=df_classification_herbert['price_class'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df).remove_columns(['__index_level_0__'])\n",
    "eval_dataset = Dataset.from_pandas(eval_df).remove_columns(['__index_level_0__'])\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"price_class\", \"labels\")\n",
    "eval_dataset = eval_dataset.rename_column(\"price_class\", \"labels\")\n",
    "\n",
    "print(f\"Zbi√≥r treningowy (wiersze): {len(train_dataset)}\")\n",
    "print(f\"Zbi√≥r walidacyjny (wiersze): {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c5a33ff-1164-42b7-a5de-77f504c2b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6ef47bf32d4e24993921b1dcc135e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26b2742e4a04964ae57dbbf772dcb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allegro/herbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"description\"], truncation=True, padding=\"max_length\")\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a93614-eab6-452c-95d6-011f51c4e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    f1_weighted = f1_score(labels, predictions, average=\"weighted\")\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bafcb8f-40cb-4ebd-a1a4-ad25b6953ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mz/Projects/adm/Otomoto_data_mining/.venv/lib/python3.13/site-packages/transformers/training_args.py:1636: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ü§ó Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./herbert_car_price_model\", \n",
    "    num_train_epochs=3, \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, \n",
    "    metric_for_best_model=\"f1_weighted\", \n",
    "    fp16=False,\n",
    "    no_cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f8990aa-b346-425e-aabf-a8b16a8d534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210fe6bd-be75-487e-8002-3baf58a4fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczƒôcie Fine-Tuning modelu HERBERT...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='3165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  88/3165 22:14 < 13:16:01, 0.06 it/s, Epoch 0.08/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Rozpoczƒôcie Fine-Tuning modelu HERBERT...\")\n",
    "train_results = trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\nWyniki walidacji po Fine-Tuning:\")\n",
    "print(eval_results)\n",
    "\n",
    "model_save_path = \"./herbert_price_classifier\"\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"\\nModel i tokenizer zapisane w: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9870a-9301-4837-a270-653bc03cdf28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PYTORCH VERSION:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "    print(\"Current CUDA device:\", torch.cuda.current_device())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"Using device: MPS (Apple Silicon GPU)\")\n",
    "else:\n",
    "    print(\"Using device: CPU\")\n",
    "    \n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f85dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_ranges = [\n",
    "    0,\n",
    "    3_000,\n",
    "    5_000,\n",
    "    10_000,\n",
    "    20_000,\n",
    "    50_000,\n",
    "    80_000,\n",
    "    100_000,\n",
    "    150_000,\n",
    "    200_000,\n",
    "    300_000,\n",
    "    400_000,\n",
    "    500_000,\n",
    "    600_000,\n",
    "    700_000,\n",
    "    800_000,\n",
    "    4_000_000,\n",
    "]\n",
    "df = clean_df.drop(\n",
    "    [\n",
    "        \"url\",\n",
    "        \"color\",\n",
    "        \"posted_date\",\n",
    "        \"price_net_info\",\n",
    "        \"location\",\n",
    "        \"price\",\n",
    "        \"country_of_origin\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "\n",
    "df[\"capacity\"] = (\n",
    "    df[\"capacity\"]\n",
    "    .str.replace(\" cm3\", \"\", regex=False)\n",
    "    .str.replace(\" \", \"\")\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df[\"power\"] = (\n",
    "    df[\"power\"].str.replace(\" \", \"\").str.replace(\"KM\", \"\", regex=False).astype(float)\n",
    ")\n",
    "\n",
    "df[\"mileage\"] = (\n",
    "    df[\"mileage\"].str.replace(\" km\", \"\", regex=False).str.replace(\" \", \"\").astype(float)\n",
    ")\n",
    "\n",
    "df[\"price_pln\"] = (\n",
    "    df[\"price_pln\"].str.replace(\" \", \"\").str.replace(\",\", \".\").astype(float)\n",
    ")\n",
    "\n",
    "df = df.dropna(\n",
    "    subset=[\n",
    "        \"model\",\n",
    "        \"condition\",\n",
    "        \"fuel\",\n",
    "        \"brand\",\n",
    "        \"body_type\",\n",
    "        \"accident_free\",\n",
    "        \"year\",\n",
    "        \"capacity\",\n",
    "        \"power\",\n",
    "        \"mileage\",\n",
    "        \"seats\",\n",
    "        \"description\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "price_ranges = [\n",
    "    0,\n",
    "    3_000,\n",
    "    5_000,\n",
    "    10_000,\n",
    "    20_000,\n",
    "    50_000,\n",
    "    80_000,\n",
    "    100_000,\n",
    "    150_000,\n",
    "    200_000,\n",
    "    300_000,\n",
    "    400_000,\n",
    "    500_000,\n",
    "    600_000,\n",
    "    700_000,\n",
    "    800_000,\n",
    "    4_000_000,\n",
    "]\n",
    "\n",
    "model_name = \"allegro/herbert-klej-cased-v1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(price_ranges)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b8efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: torch.tensor(val[idx]) for key, val in self.encodings.items()\n",
    "        } | {\n",
    "            \"labels\": torch.tensor(self.labels[idx])   # ‚Üê here labels[idx] is str\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61fa118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df[\"description\"].tolist()\n",
    "y = pd.cut(df[\"price_pln\"], bins=price_ranges, labels=False).astype(int).tolist()\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_enc = tokenizer(X_train, truncation=True, padding=True, max_length=256)\n",
    "test_enc = tokenizer(X_test, truncation=True, padding=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f568baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "train_dataset = PriceDataset(train_enc, y_train)\n",
    "test_dataset = PriceDataset(test_enc, y_test)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./model-training',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trainer.predict(test_dataset)\n",
    "pred_class = pred.predictions.argmax(axis=1)\n",
    "print(\"Accuracy:\", (pred_class == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # tokenize a single string\n",
    "    enc = tokenizer(\n",
    "        [text],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**enc.to(model.device))\n",
    "        probs = outputs.logits.softmax(dim=1)\n",
    "        cls_id = probs.argmax(dim=1).item()\n",
    "    \n",
    "\n",
    "    return price_ranges[cls_id]\n",
    "\n",
    "predict(\"MERCEDES SPRINTER 2.2CDI 164KM Z 2020 ROKU PRODUKCJI Z PRZEBIEGIEM 168TYS KM Z AUTOMATYCZNƒÑ SKRZYNIƒÑ BIEG√ìW\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd3e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "print(\"accuracy:\", accuracy_score(y_test, pred_class))\n",
    "print(\"\\nreport:\\n\", classification_report(y_test, pred_class))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_class)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"true\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
